{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mclcavalcante/hard-hat-detection/blob/main/Helmet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import"
      ],
      "metadata": {
        "id": "8JdAe-c4AG1x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Zh0EHiB_c0F"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "from pathlib import Path\n",
        "from xml.dom.minidom import parse\n",
        "from shutil import copyfile\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare Data for YOLOv5 Format"
      ],
      "metadata": {
        "id": "uz-HAAp1AEx9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DEFs"
      ],
      "metadata": {
        "id": "kiM8Yv53BJmA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_annot(size , box):\n",
        "    x1 = int(box[0])\n",
        "    y1 = int(box[1])\n",
        "    x2 = int(box[2])\n",
        "    y2 = int(box[3])\n",
        "\n",
        "    dw = np.float32(1. / int(size[0]))\n",
        "    dh = np.float32(1. / int(size[1]))\n",
        "\n",
        "    w = x2 - x1\n",
        "    h = y2 - y1\n",
        "    x = x1 + (w / 2)\n",
        "    y = y1 + (h / 2)\n",
        "\n",
        "    x = x * dw\n",
        "    w = w * dw\n",
        "    y = y * dh\n",
        "    h = h * dh\n",
        "    return [x, y, w, h]"
      ],
      "metadata": {
        "id": "d1Qw9jb6_-Qf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_txt_file(img_jpg_file_name, size, img_box):\n",
        "    save_file_name = '/kaggle/working/Dataset/labels/' +  img_jpg_file_name + '.txt'\n",
        "    print(save_file_name)\n",
        "    #file_path = open(save_file_name, \"a+\")\n",
        "    with open(save_file_name ,'a+') as file_path:\n",
        "        for box in img_box:\n",
        "\n",
        "            cls_num = classes.index(box[0])\n",
        "\n",
        "            new_box = convert_annot(size, box[1:])\n",
        "\n",
        "            file_path.write(f\"{cls_num} {new_box[0]} {new_box[1]} {new_box[2]} {new_box[3]}\\n\")\n",
        "\n",
        "        file_path.flush()\n",
        "        file_path.close()"
      ],
      "metadata": {
        "id": "3IjK1yLZBUCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_xml_data(file_path, img_xml_file):\n",
        "    img_path = file_path + '/' + img_xml_file + '.xml'\n",
        "\n",
        "    dom = parse(img_path)\n",
        "    root = dom.documentElement\n",
        "    img_name = root.getElementsByTagName(\"filename\")[0].childNodes[0].data\n",
        "    img_size = root.getElementsByTagName(\"size\")[0]\n",
        "    objects = root.getElementsByTagName(\"object\")\n",
        "    img_w = img_size.getElementsByTagName(\"width\")[0].childNodes[0].data\n",
        "    img_h = img_size.getElementsByTagName(\"height\")[0].childNodes[0].data\n",
        "    img_c = img_size.getElementsByTagName(\"depth\")[0].childNodes[0].data\n",
        "\n",
        "    img_box = []\n",
        "    for box in objects:\n",
        "        cls_name = box.getElementsByTagName(\"name\")[0].childNodes[0].data\n",
        "        x1 = int(box.getElementsByTagName(\"xmin\")[0].childNodes[0].data)\n",
        "        y1 = int(box.getElementsByTagName(\"ymin\")[0].childNodes[0].data)\n",
        "        x2 = int(box.getElementsByTagName(\"xmax\")[0].childNodes[0].data)\n",
        "        y2 = int(box.getElementsByTagName(\"ymax\")[0].childNodes[0].data)\n",
        "\n",
        "        img_jpg_file_name = img_xml_file + '.jpg'\n",
        "        img_box.append([cls_name, x1, y1, x2, y2])\n",
        "\n",
        "\n",
        "    # test_dataset_box_feature(img_jpg_file_name, img_box)\n",
        "    save_txt_file(img_xml_file, [img_w, img_h], img_box)"
      ],
      "metadata": {
        "id": "4C4StP7jBWDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Files"
      ],
      "metadata": {
        "id": "yxPheIXoBQ1q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p Dataset/labels\n",
        "!mkdir -p Dataset/images"
      ],
      "metadata": {
        "id": "tlmNAd0BA817"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = ['helmet','head','person']"
      ],
      "metadata": {
        "id": "Xr2obhYNA-gm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgXLj7TvCTrC",
        "outputId": "f006dc46-1881-4a8a-ce78-9d7ea71bd39a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files = os.listdir('/content/drive/MyDrive/IA_8p/hard-hat-detection/Annotations')\n",
        "#files = os.listdir('/kaggle/input/hard-hat-detection/annotations')\n",
        "for file in files:\n",
        "    print(\"file name: \", file)\n",
        "    file_xml = file.split(\".\")\n",
        "    print(file_xml[0])\n",
        "    #get_xml_data('/content/drive/MyDrive/IA_8p/hard-hat-detection/Annotations', file_xml[0])"
      ],
      "metadata": {
        "id": "l8WUkzBzAKQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train / Test"
      ],
      "metadata": {
        "id": "BnLuN5_9BYV1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "image_list = os.listdir('/content/drive/MyDrive/IA_8p/hard-hat-detection/Images')\n",
        "train_list, test_list = train_test_split(image_list, test_size=0.2, random_state=42)\n",
        "val_list, test_list = train_test_split(test_list, test_size=0.5, random_state=42)\n",
        "print('total =',len(image_list))\n",
        "print('train :',len(train_list))\n",
        "print('val   :',len(val_list))\n",
        "print('test  :',len(test_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pObMaW8SBb5H",
        "outputId": "e26dc8c9-6893-45f1-9eb0-b194f096bcdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total = 5000\n",
            "train : 4000\n",
            "val   : 500\n",
            "test  : 500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def copy_data(file_list, img_labels_root, imgs_source, mode):\n",
        "\n",
        "    root_file = Path( '/kaggle/working/Dataset/images/'+  mode)\n",
        "    if not root_file.exists():\n",
        "        print(f\"Path {root_file} does not exit\")\n",
        "        os.makedirs(root_file)\n",
        "\n",
        "    root_file = Path('/kaggle/working/Dataset/labels/' + mode)\n",
        "    if not root_file.exists():\n",
        "        print(f\"Path {root_file} does not exit\")\n",
        "        os.makedirs(root_file)\n",
        "\n",
        "    for file in file_list:\n",
        "        img_name = file.replace('.png', '')\n",
        "        img_src_file = imgs_source + '/' + img_name + '.png'\n",
        "        label_src_file = img_labels_root + '/' + img_name + '.txt'\n",
        "\n",
        "        #print(img_sor_file)\n",
        "        #print(label_sor_file)\n",
        "        # im = Image.open(rf\"{img_sor_file}\")\n",
        "        # im.show()\n",
        "\n",
        "        # Copy image\n",
        "        DICT_DIR = '/kaggle/working/Dataset/images/'  + mode\n",
        "        img_dict_file = DICT_DIR + '/' + img_name + '.png'\n",
        "\n",
        "        copyfile(img_src_file, img_dict_file)\n",
        "\n",
        "        # Copy label\n",
        "        DICT_DIR = '/kaggle/working/Dataset/labels/' + mode\n",
        "        img_dict_file = DICT_DIR + '/' + img_name + '.txt'\n",
        "        copyfile(label_src_file, img_dict_file)"
      ],
      "metadata": {
        "id": "1bclsJ3BBb9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "copy_data(train_list, '/kaggle/working/Dataset/labels', '/kaggle/input/hard-hat-detection/images', \"train\")\n",
        "copy_data(val_list,   '/kaggle/working/Dataset/labels', '/kaggle/input/hard-hat-detection/images', \"val\")\n",
        "copy_data(test_list,  '/kaggle/working/Dataset/labels', '/kaggle/input/hard-hat-detection/images', \"test\")"
      ],
      "metadata": {
        "id": "ibrs3tQQBhN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls drive/MyDrive/IA_8p/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQCStxiJBkkR",
        "outputId": "60c723cd-8b66-413b-8c6c-4c213f138e55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hard-hat-detection  Helmet.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get YOLOv5 Model"
      ],
      "metadata": {
        "id": "pZCRB-FCBlhU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/MyDrive/IA_8p/\n",
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQzzJS7FBond",
        "outputId": "91860092-1e09-49b4-9815-6ef5e6b12430"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/IA_8p\n",
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 16026, done.\u001b[K\n",
            "remote: Counting objects: 100% (59/59), done.\u001b[K\n",
            "remote: Compressing objects: 100% (34/34), done.\u001b[K\n",
            "remote: Total 16026 (delta 33), reused 41 (delta 25), pack-reused 15967\u001b[K\n",
            "Receiving objects: 100% (16026/16026), 14.68 MiB | 13.75 MiB/s, done.\n",
            "Resolving deltas: 100% (10999/10999), done.\n",
            "/content/drive/MyDrive/IA_8p/yolov5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "\n",
        "dict_file = {'train':'/content/drive/MyDrive/IA_8p/hard-hat-detection/Images/train' ,\n",
        "            'val': '/content/drive/MyDrive/IA_8p/hard-hat-detection/Images/val',\n",
        "            'nc' : '3',\n",
        "            'names' : ['helmet','head','person']}\n",
        "\n",
        "with open('/content/drive/MyDrive/IA_8p/yolov5/data/hard_head.yaml', 'w+') as file:\n",
        "    documents = yaml.dump(dict_file, file)"
      ],
      "metadata": {
        "id": "XflF2P7KBqTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Net"
      ],
      "metadata": {
        "id": "m7iY2JNZB04P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb disabled"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePtropArB34o",
        "outputId": "92bffdcf-444e-4682-ced7-cff757dd068a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: wandb: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --img 416 --batch 32 --epochs 30 --data data/hard_head.yaml --cfg models/yolov5s.yaml --weights yolov5s.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hy5me2s_B5BW",
        "outputId": "5cb00442-c2ff-4ac4-d3d8-1f8dee3e1119"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-10-28 20:29:05.455967: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-10-28 20:29:05.456040: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-10-28 20:29:05.456085: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=models/yolov5s.yaml, data=data/hard_head.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=30, batch_size=32, imgsz=416, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 âœ…\n",
            "YOLOv5 ðŸš€ v7.0-230-g53efd07 Python-3.10.12 torch-2.1.0+cu118 CPU\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 ðŸš€ runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 13.4MB/s]\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5s.pt...\n",
            "100% 14.1M/14.1M [00:00<00:00, 88.5MB/s]\n",
            "\n",
            "Overriding model.yaml nc=80 with nc=3\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     21576  models.yolo.Detect                      [3, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "YOLOv5s summary: 214 layers, 7027720 parameters, 7027720 gradients, 16.0 GFLOPs\n",
            "\n",
            "Transferred 342/349 items from yolov5s.pt\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/IA_8p/yolov5/utils/dataloaders.py\", line 481, in __init__\n",
            "    assert self.im_files, f'{prefix}No images found'\n",
            "AssertionError: \u001b[34m\u001b[1mtrain: \u001b[0mNo images found\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/IA_8p/yolov5/train.py\", line 647, in <module>\n",
            "    main(opt)\n",
            "  File \"/content/drive/MyDrive/IA_8p/yolov5/train.py\", line 536, in main\n",
            "    train(opt.hyp, opt, device, callbacks)\n",
            "  File \"/content/drive/MyDrive/IA_8p/yolov5/train.py\", line 195, in train\n",
            "    train_loader, dataset = create_dataloader(train_path,\n",
            "  File \"/content/drive/MyDrive/IA_8p/yolov5/utils/dataloaders.py\", line 124, in create_dataloader\n",
            "    dataset = LoadImagesAndLabels(\n",
            "  File \"/content/drive/MyDrive/IA_8p/yolov5/utils/dataloaders.py\", line 483, in __init__\n",
            "    raise Exception(f'{prefix}Error loading data from {path}: {e}\\n{HELP_URL}') from e\n",
            "Exception: \u001b[34m\u001b[1mtrain: \u001b[0mError loading data from /content/drive/MyDrive/IA_8p/hard-hat-detection/Images/train: \u001b[34m\u001b[1mtrain: \u001b[0mNo images found\n",
            "See https://docs.ultralytics.com/yolov5/tutorials/train_custom_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Detect"
      ],
      "metadata": {
        "id": "wg2N8l8SB97P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --source /kaggle/working/Dataset/images/test  --weights yolov5s.pt --conf 0.25"
      ],
      "metadata": {
        "id": "PmchbkP-CAcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image"
      ],
      "metadata": {
        "id": "3CJtelspCDQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "testfiles = glob('runs/detect/exp3/*')\n",
        "\n",
        "img = plt.imread(testfiles[28])\n",
        "plt.imshow(img)\n",
        "plt.show"
      ],
      "metadata": {
        "id": "TIx7wT-FCFKb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}